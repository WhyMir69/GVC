{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT NOTE\n",
    "- if mo ask si maam why this is similar to mine and mag suspect siya na i made it, kay just tell her na youre using mediapipe instead of tensorflow\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flaw/weaknesses observed:\n",
    "\n",
    "evident luminance affecting performance, resulting to erratic tracking which causing it to abruptly stop collecting and considering it as one execution\n",
    "- should always perform/collect data at a well lit environment\n",
    "- should apply frame patience mechanism wherein it ignores certain amount of frames before it consider as an execution [APPLIED!]\n",
    "\n",
    "overload of data\n",
    "- apply frame buffering(less frame already is sufficient enough to resemble the movement)\n",
    "- eliminate z coordinate(pose estimation is positional dependant)\n",
    "- experiment on lessening decimal places (this would sacrifice a certain amount of accuracy, should heavily consider how much of it)\n",
    "\n",
    "\n",
    "future planned features\n",
    " - real-time frame by frame visualization every after execution to check\n",
    " - easy-delete button wherein it deletes the current execution collected in case its not good or intended \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How data collection works?\n",
    "1) show your hands on the camera----------------> data collection starts\n",
    "2) perform the action you want -----------------> coordinates are collected(coordinates_frame are generated and are compiled in coordinates_movemenet )\n",
    "3) remove your hand from the camera ------------> data collection stops(coordinates_movemenet is compiled in execution)\n",
    "4) repeat...\n",
    "\n",
    "coordinates\n",
    "- individual X and Y coordinates tracked and collected \n",
    "- how it looks like: 0.435. 0.454....etc\n",
    "\n",
    "\n",
    "coordinates_frame\n",
    "- compilation of coordinates\n",
    "- how it looks like: [coordinates, coordinates, coordinates, coordinates..., coordinates,]\n",
    "\n",
    "execution\n",
    "- compilation of coordinates_frame, which resembles a movement \n",
    "- how it looks like:\n",
    "[\n",
    "[coordinates, coordinates, coordinates, coordinates..., coordinates,],\n",
    "[coordinates, coordinates, coordinates, coordinates..., coordinates,],\n",
    "...\n",
    "[coordinates, coordinates, coordinates, coordinates..., coordinates,],\n",
    "]\n",
    "\n",
    "datasets\n",
    "- compilation of executions\n",
    "- how it looks like:\n",
    "[\n",
    "execution,\n",
    "execution,\n",
    "execution,\n",
    "...\n",
    "execution,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "from threading import Thread\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Globals\n",
    "detection_mode = \"Multiple\"\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "label_map = {}\n",
    "trained = False\n",
    "\n",
    "# MediaPipe for hand tracking\n",
    "mp_hands = mp.solutions.hands\n",
    "hands_detector = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.7)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "known_folder = os.path.join(os.getcwd(), \"datasets/\")\n",
    "parent_folder = os.path.dirname(known_folder)\n",
    "file_path = os.path.join(parent_folder, \"output.txt\")\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pose_estimation():\n",
    "    frame_buffer= 8\n",
    "    frame_buffer_ctr = 0\n",
    "\n",
    "    frame_patience = 8\n",
    "    frame_patience_ctr = 0\n",
    "    \n",
    "    coordinates_frame = []\n",
    "    coordinates_movemenet = []\n",
    "    execution = []\n",
    "\n",
    "    while True:        \n",
    "        frame_buffer_ctr+=1\n",
    "        if frame_buffer_ctr>=frame_buffer:   \n",
    "            frame_buffer_ctr = 0         \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands_detector.process(rgb)\n",
    "\n",
    "            if results.multi_hand_landmarks:    \n",
    "                frame_patience_ctr=0\n",
    "\n",
    "                for hand_landmarks in results.multi_hand_landmarks:            \n",
    "                    mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)             \n",
    "                    for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                        coordinates_frame.append(f\"{landmark.x:.3f}\")\n",
    "                        coordinates_frame.append(f\"{landmark.y:.3f}\")     \n",
    "                coordinates_movemenet.append(coordinates_frame)\n",
    "                coordinates_frame=[]\n",
    "            else:\n",
    "                if frame_patience_ctr<=frame_patience:\n",
    "                    frame_patience_ctr += 1\n",
    "\n",
    "                if frame_patience_ctr >= frame_patience:\n",
    "                    if len(coordinates_movemenet) != 0:    \n",
    "                        execution.append(coordinates_movemenet)\n",
    "                        print(\"execution collected -> \", len(execution),\"[\",len(coordinates_movemenet) ,\"]\")\n",
    "\n",
    "                        coordinates_movemenet = []\n",
    "\n",
    "            cv2.imshow(\"Recording Face and Hand\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()  \n",
    "    return execution\n",
    "\n",
    "def text_encode(coordinates_data):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        for execution in coordinates_data:\n",
    "            file.write(\"START\\n\")\n",
    "            for movement_coordinates in execution:\n",
    "                for coordinate in movement_coordinates:\n",
    "                    file.write(str(coordinate))\n",
    "                    file.write(\"|\")\n",
    "                file.write(\"\\n\")\n",
    "            file.write(\"END\\n\")\n",
    "\n",
    "\n",
    "def text_decode(file_path):\n",
    "    coordinates_data = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    execution = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line == \"START\":\n",
    "            execution = []\n",
    "        elif line == \"END\":\n",
    "            coordinates_data.append(execution)\n",
    "        else:\n",
    "            str_coords = line.split(\"|\")[:-1]\n",
    "            float_coords = [float(coord) for coord in str_coords]\n",
    "            execution.append(float_coords)\n",
    "\n",
    "    return coordinates_data\n",
    "\n",
    "\n",
    "\n",
    "def initialize_dummy_dataset():\n",
    "    frame_coordinate = []\n",
    "    movement_coordinate = []\n",
    "    executions = []\n",
    "\n",
    "    for x in range(60):\n",
    "        frame_coordinate.append(0.69)\n",
    "\n",
    "    for i in range(random.randint(8, 15)):    \n",
    "        for x in range(random.randint(8, 15)):\n",
    "            movement_coordinate.append(frame_coordinate)\n",
    "        executions.append(movement_coordinate)\n",
    "        movement_coordinate = []\n",
    "\n",
    "    return executions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinates_visualization(coordintes_dataset):\n",
    "    canvas_size = 500\n",
    "    canvas = np.zeros((canvas_size, canvas_size * 2, 3), dtype=np.uint8)\n",
    "\n",
    "    # for execution in coordintes_dataset:\n",
    "        # for frame_coordinates in execution[0]:\n",
    "        #     # for individual_coordinates in frame_coordinates:\n",
    "        #     for individual_coordinates in range(len(frame_coordinates)):\n",
    "        #         if individual_coordinates + 1 < len(frame_coordinates):\n",
    "        #             if individual_coordinates % 2 != 0:\n",
    "        #                 cv2.circle(canvas, (int(frame_coordinates[individual_coordinates]*1000),int(frame_coordinates[individual_coordinates+1]*1000)), radius=4, color=(0, 255, 0), thickness=-1)\n",
    "    print(len(coordintes_dataset[0]))\n",
    "    for frame_coordinates in coordintes_dataset[0]:\n",
    "        # for individual_coordinates in frame_coordinates:\n",
    "        for individual_coordinates in range(len(frame_coordinates)):\n",
    "            if individual_coordinates + 1 < len(frame_coordinates):\n",
    "                if individual_coordinates % 2 != 0:\n",
    "                    cv2.circle(canvas, (int(frame_coordinates[individual_coordinates]*1000),int(frame_coordinates[individual_coordinates+1]*1000)), radius=4, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "    cv2.imshow(\"Painted Coordinates\", canvas)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_encode(pose_estimation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coordinates_visualization(text_decode(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
